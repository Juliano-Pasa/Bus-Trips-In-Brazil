{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5928581-fbe8-4d9f-af11-5f986fc4db1f",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc0ee74d-20de-4d41-85aa-c24fac82588d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir, path\n",
    "\n",
    "from buspkg import DBFunctions as db\n",
    "from buspkg import ProcessData\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c32f5d-50eb-4d00-a787-7b7e7381b810",
   "metadata": {},
   "source": [
    "# Connect to DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0865dfd0-edfc-4415-8095-a6280a53df75",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = db.GetDefaultConnection()\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8d3343-f2d1-47c2-bdfc-1097f9169eb8",
   "metadata": {},
   "source": [
    "## Retrieving file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec1f2b75-82df-4365-8d9a-bbd2bbf80ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = \"../data/rawfiles/\"\n",
    "filePaths = [dataPath + f for f in listdir(dataPath) if path.isfile(dataPath + f)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c998c7f5-b41d-4f30-b555-5327438ab14b",
   "metadata": {},
   "source": [
    "## Discover encoding of csv files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34d68aa-7525-4d52-83d4-88b45fda2e11",
   "metadata": {},
   "source": [
    "First step to make sure files are being read in their correct encoding. This is important so no information is lost and no encoding errors occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f009fbfa-4d32-4c14-bac4-706a7f6392f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "encodings = {}\n",
    "\n",
    "for file in filePaths:\n",
    "    encodings[file] = ProcessData.DiscoverFileEncoding(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26f24ed-249e-4d0c-b65b-04b9ed60a0fc",
   "metadata": {},
   "source": [
    "## Visualizing basic information about the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5079f25-e4fa-4638-bca0-35e42c694034",
   "metadata": {},
   "source": [
    "Load first file to understand column ranges, distribution and types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63c83c54-185f-42d5-a6fd-6e7628866959",
   "metadata": {},
   "outputs": [],
   "source": [
    "colTypes = {\n",
    "    'codigo_viagem':'str', \n",
    "    'cnpj':'str',\n",
    "    'placa':'str',\n",
    "    'nu_linha':'str',            \n",
    "    'tipo_viagem':'str',\n",
    "    'data_viagem_programada':'str',\n",
    "    'hora_viagem_programada':'str',\n",
    "    'data_inicio_viagem':'str',\n",
    "    'data_fim_viagem':'str',\n",
    "    'sentido_linha':'str',\n",
    "    'latitude':np.float64,\n",
    "    'longitude':np.float64,\n",
    "    'pdop':np.float64,\n",
    "    'numero_imei':'str',\n",
    "    'in_transbordo':'str',\n",
    "    'codigo_viagem_transbordo':'str'\n",
    "}\n",
    "\n",
    "filePath = filePaths[0]\n",
    "encoding = encodings[filePath]\n",
    "basicStatsDF = pd.read_csv(filePath, encoding=encoding['encoding'], delimiter=';', header=0, dtype=colTypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a42c1d2-c74c-4282-8613-450e307c2fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "codigo_viagem  codigo_viagem\n",
      "7              7                100251\n",
      "Name: count, dtype: int64\n",
      "\n",
      "cnpj  cnpj\n",
      "14    14      100251\n",
      "Name: count, dtype: int64\n",
      "\n",
      "nu_linha  nu_linha\n",
      "8         8           100251\n",
      "Name: count, dtype: int64\n",
      "\n",
      "placa  placa\n",
      "7      7        100251\n",
      "Name: count, dtype: int64\n",
      "\n",
      "numero_imei  numero_imei\n",
      "15           15             100251\n",
      "Name: count, dtype: int64\n",
      "\n",
      "tipo_viagem  tipo_viagem\n",
      "1            1              100251\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "codeSizes = basicStatsDF[\"codigo_viagem\"].str.len()\n",
    "print(codeSizes.groupby(codeSizes).value_counts())\n",
    "print()\n",
    "\n",
    "cnpjSizes = basicStatsDF[\"cnpj\"].str.len()\n",
    "print(cnpjSizes.groupby(cnpjSizes).value_counts())\n",
    "print()\n",
    "\n",
    "lineSizes = basicStatsDF[\"nu_linha\"].str.len()\n",
    "print(lineSizes.groupby(lineSizes).value_counts())\n",
    "print()\n",
    "\n",
    "plateSizes = basicStatsDF[\"placa\"].str.len()\n",
    "print(plateSizes.groupby(plateSizes).value_counts())\n",
    "print()\n",
    "\n",
    "imeiSizes = basicStatsDF[\"numero_imei\"].str.len()\n",
    "print(imeiSizes.groupby(imeiSizes).value_counts())\n",
    "print()\n",
    "\n",
    "typeSizes = basicStatsDF[\"tipo_viagem\"].str.len()\n",
    "print(typeSizes.groupby(typeSizes).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f1806a-4199-4037-9374-b87406917e3f",
   "metadata": {},
   "source": [
    "## Processing and writing data to DB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3556cbe-68da-4bdc-a93d-79e0c4bbfc69",
   "metadata": {},
   "source": [
    "As data is being read, it will be processed and saved to the DB in batches. Since there is a lot of files, there is a chance that some errors can occur during processing and writing. Because of this, a pickle file will be used as checkpoint to store what files were properly written in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0312432e-5898-4499-a115-1c049c25de2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tableName = \"RegularTrips\"\n",
    "encoding = next(iter(encodings.values()))['encoding']\n",
    "pickleFilePath = \"../data/checkpoints/RawDataProcessingCheckpoint.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "447970b3-99b5-4225-a69c-3ba166a623df",
   "metadata": {},
   "outputs": [],
   "source": [
    "processedFiles = ProcessData.GetPickleCheckpoint(pickleFilePath)\n",
    "if not processedFiles:\n",
    "    processedFiles = set([])\n",
    "\n",
    "for filePath in filePaths:\n",
    "    if filePath in processedFiles:\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        batch = ProcessData.ProcessRawTripFile(filePath, encoding)\n",
    "        db.WriteBatchToDB(batch, tableName, cur, conn)\n",
    "        conn.commit()\n",
    "    except Exception as e:\n",
    "        conn.rollback()\n",
    "        print(e)\n",
    "        print(f\"Error while processing raw trip data: {filePath}. Rolling back any possible database action.\")\n",
    "    else:\n",
    "        processedFiles.add(filePath)\n",
    "        ProcessData.SavePickleCheckpoint(pickleFilePath, processedFiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce86e82-f2a8-481d-b7d0-d682bc6bc659",
   "metadata": {},
   "source": [
    "## Creating indices for relevant fields in the database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0de41c-0218-4dee-b45c-5844a9d745d1",
   "metadata": {},
   "source": [
    "Although this is a bit off the responsabilities of this notebook, we should ideally create these indices only after inserting the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7051840e-33a7-4bc2-bf8c-354f80ad84ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"CREATE INDEX IF NOT EXISTS cnpjIdx ON RegularTrips(cnpj)\"\n",
    "db.ExecuteQuery(query, cur, conn)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "489e7c52-5916-4039-97f4-919ba94bfd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"CREATE INDEX IF NOT EXISTS plateIdx on RegularTrips(plate)\"\n",
    "db.ExecuteQuery(query, cur, conn)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0894df2f-eab8-42f2-b3e9-615857125fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
